---
title: "Spreading: Spanish University Email Network"
author: "Yijia Lin and Bradley McKenzie"
date: "`r Sys.Date()`"
output: 
  rmdformats::html_clean:
    lightbox: false
    thumbnails: false
    toc: yes
    toc_float: true
    toc_depth: 3
editor_options: 
  markdown: 
    wrap: 72
---

```{r,include=F}
knitr::opts_chunk$set(cache=T,message=FALSE,warning=FALSE)
options(scipen=700)
```

## Libraries

```{r, message=FALSE, warning=FALSE}
rm(list = ls())
library(tidyverse)
library(igraph)
library(tidygraph)
library(ggplot2)
library(ggraph)
library(ggthemes)
library(here)
library(caret)
```

## Read the data

```{r, message=FALSE, warning=FALSE}
nodes <- read_csv(here("network_data", "nodes.csv"))
links <- read_csv(here("network_data", "edges.csv"))
```

## Description of the dataset

This network is a directed and unweighted social communication network,
which represents the exchange of emails among members of the Rovira i
Virgili University in Spain, in 2003.

Source: [Netzschleuder](https://networks.skewed.de/net/uni_email).

### Interpreting the email dataset as a SIR model

To help interpret the findings within the context of the university
email network, we explain the following settings can specify the
following settings. In the setting of a university email network We can
consider the epidemic as the spread of rumors between individuals. For
example, it could be some sort of negative campaign about a Professor to
ruin their reputation (but never a Social Networks teacher obviously -
don't worry Blas, you're safe :D).

We could the actors in the model:

-   Susceptible (S): Individuals who have not yet received the email

-   Infected (I): Individuals who have already recieved the bad email
    and joined the campaign. They can now send the rumors on to other
    individuals in the university

-   Recovered (R): Individuals who have already received the bad email
    and were infected, but now realize that it's just a rumor and are
    now not at risk of believing the email if they see it again AND will
    not send it to others if they see it. They are immune to the rumor.

We could consider the email as a SI model if it's

### Understanding this model stype:

In terms of model outcome, we could consider the outcomes as:

Susceptible-Infected (SI): Everyone who received the virus is infected
and loses control of their computer and the virus can be sent on to all
of their connections. (This is the least difficult to justify in this
setting)

Susceptible-Infected-Recovered (SIR): Everyone who received the email
virus has installed proper seucity software and is not as risk of
receiving anymore malware.

Susceptible-Infected-Susceptible (SIS): People have IT make a temporary
fix to remove the email virus, but it is not a long term solution. The
computer does not have immunity.

#### Nodes and links

```{r}
head(nodes)
head(links)
```

Within the `nodes` dataframe, the column `# index` is the one indicating
the index of the nodes, the column `name` would contain the
corresponding name of each node, but they have been anonymized for
privacy reason so this column is still a series of numbers. The `_pos`
column represents the coordinates of each node in a 2D space, used for
visualization or layout in graph-related tasks.

In the `links` dataframe, the column `# source` and `target` indicate
the indexes of the 2 nodes forming a link.

#### Graph

```{r}
graph <- graph_from_data_frame(links, directed = TRUE, vertices = nodes)
graph
```

## Initial graph exploration

To understand the graph, we can plot the degree distribution to check
whether we have the expected power-law distribution or another type.
This will help to interpret the findings later when we remove links.

First, we check for any loops, these would be emails sent to self. And
if so, we can simplify the graph to remove these (and also any eventual
multiple edge).

```{r}
paste0("The number of recursive (self-directed) emails in the network is: ", 
       ecount(graph) - ecount(simplify(graph)))

# we see that one exists, so we simplify the graph to remove it. 
graph <- simplify(graph)

# check our graph is setup properly
is_igraph(graph)
```

Next, calculate basic descriptive statistics of the plot:

```{r}
paste0("There are ", vcount(graph), " nodes and ", ecount(graph), " edges in our Spanish email network")

# check if our graph is fully connected
is_connected(graph)

#degree
degree_all <- degree(graph, mode="all")
degree_out <- degree(graph, mode="out")
paste0("The average degree is: ", round(mean(degree(graph)), 2), " when we DO NOT consider the direction of the emails.")
paste0("The average degree is: ", round(sum(degree_out)/vcount(graph), 2), " when we DO consider the emails to be directed outward from the node (sender) to a recipient")

# most connected node:
paste0("The most connected node is number ", which.max(degree(graph))[1], " which has ", max(degree(graph)), " links.")
```

For the purposes of this homework, we are not factoring in this
directional property of the graph. We are considering that the emails
are indicating a social relationship between the two nodes (sender and
receiver) and it is irrelevant who sent the email. This means the
average interactions for each individual node is 19.24 (which would
represent email interactions with 19.24 different people on average).

Now check the degree distribution;

```{r, fig.width=8}
# set average node for label 
avg_deg <- round(mean(degree(graph)),2)

# plot linear distribution
ggplot() + 
  geom_histogram(aes(x = degree_all), bins=40) + 
  geom_vline(aes(xintercept = avg_deg, colour = "red"), show.legend = FALSE) +
  annotate("text", x = avg_deg+5, y = 160, label = paste0("Avg deg = ", avg_deg), angle = 90, color = "red") + 
  labs(title = "Degree distribution histogram for Uni emails",
       x = "Degrees",
       y = "Number of nodes") +
  theme(axis.title.y = element_text(angle = 90))
```

We see the common power law distribution. There are few very connected
nodes and many less connected nodes. We see that the max node must be
node number 105 we reported earlier, with its 142 links. This is far
more than the second most connected.

Visualization of the network:

```{r, fig.width=8}
# set colour and size only for the top 50 nodes
top_50_nodes <- order(degree_all, decreasing = TRUE)[1:50]
V(graph)$color <- "grey3"
V(graph)[top_50_nodes]$color <- "red"
V(graph)$size <- 0.75
V(graph)[top_50_nodes]$size <- 2

# plot the full network
ggraph(graph, layout = "kk") +
  geom_edge_link(width = 0.1, alpha = 0.5, color = "grey") +  
  geom_node_point(color = V(graph)$color, size = V(graph)$size) +  
  theme_void() +  
  ggtitle("Visualisation of the network, 50 most connected nodes highlighted")+
  theme(legend.position = "none")
```

We see that the most connected nodes are all centered in the graph. On
the outside, we can see the nodes with only a couple of connections.

## Steps

### 1) Find the theoretical epidemic threshold for your network for the information βc to reach a significant number of nodes.

The formula to calculate the theoretical epidemic threshold that we
learned from class is:

$$ \beta_c = \mu \frac{\langle k \rangle}{\langle k^2 \rangle}$$

where:

-   **μ (mu)**: Recovery rate — typically set to **0.1** in SIR models.

-   **⟨k⟩ (mean degree)**: The **average number of connections** (edges)
    per node in the network.

-   **⟨k²⟩ (mean squared degree)**: The **average of the square of each
    node’s degree** — it captures how much variability (or inequality)
    there is in node connectivity.

#### Updating our network to be undirected

Firstly, we make our network undirected. We use this to create a more
true social network where spreading is symmetric between nodes and can
happen either way.

We use the undirected_graph function from igraph with mode="collapse" to
update the graph. The effect of this is:

-   It merges reciprocal edges (A→B and B→A) into one link, which
    matches the idea of a “social tie”.

That’s why with collapse, the number of edges drops by half. this better
reflects the true number of relationships.

```{r}
# Create the undirected version of the graph
graph <- as_undirected(graph, mode = "collapse")

paste0("There are ", vcount(graph), " nodes and ", ecount(graph), " edges in our undirected Spanish email network.")


```

Now we start to calculate epidemic threshold using degree moments:

```{r}
# Set recovery rate (mu) — use the standard 0.1 value
mu <- 0.1

# Calculate degree of each node
k <- degree(graph)

# Mean degree and mean squared degree
mean_k <- mean(k)
mean_k2 <- mean(k^2)

# Calculate threshold with our formula: βc = μ * <k> / <k^2>
beta_c <- mu * mean(degree(graph)) / (mean(degree(graph)^2))

# Output the result
paste0("Theoretical epidemic threshold βc is approximately: ", round(beta_c, 5),
       " because ⟨k²⟩ = ", round(mean_k2, 4), " > ⟨k⟩ = ", round(mean_k, 4))

```

The estimated threshold βc ≈ 0.00535 is **very low**, indicating that
even a small infection rate β would allow the information to reach a
significant portion of the network.

This low threshold is a direct consequence of the high variance in
degree:\

⟨k⟩ = 9.62 but ⟨k²⟩ = 179.82, which suggests the presence of a few nodes
with **very high degree** (i.e., “super spreaders”).

The large gap between ⟨k⟩ and ⟨k²⟩ is a signature of **heterogeneity**
in the network. This is typical in real-world social networks, where
most people have few contacts, and a few individuals are highly
connected.

<br> <br>

### 2) Assuming that randomly-selected 1% initial spreaders, simulate the SIR model below and above that threshold and plot the number of infected people as a function of β.

Here we simulate the SIR model with different β values. In the model,
the values represent:

-   0 = S, 1 = I, 2 = R

The broad process is:

1.  Set the inputs - graph, threshold, recovery rate & seeds.

2.  Initialise all nodes as 0 in period 0, except infected which are the
    randomly assigned seeds.

3.  Create output table with time and infection period

4.  Loop through while there are still infected people. Adding new
    infections to the table in the period they became infected.

All nodes start as value 0 as they're uninfected. We then apply
infection to the randomly selected seeds and

```{r}
# Set recovery rate μ
mu <- 0.1

# SIR simulation function

sim_sir <- function(g, beta, mu, seeds){
  
  state <- rep(0, vcount(g))     
  state[seeds] <- 1              # set initial spreaders
  t <- 0
  
  table <- data.frame(t=0, inf=seeds)
  while(sum(state == 1) > 0){    
    t <- t + 1
    new_inf <- c()
    for(i in which(state == 1)){ # among all infected ones
      neighbors <- neighbors(g, i)
      for(j in neighbors){
        if(state[j] == 0 && runif(1) < beta){  
          # If neighbor j is susceptible (i.e., state[j] == 0), then infect it with probability β. "runif(1) < beta" means to generate a random number between 0 and 1. If it’s less than β, the infection is considered successful.
          new_inf <- c(new_inf, j)
        }
      }
      if(runif(1) < mu){  # Recover an infected node with probability μ
        state[i] <- 2
      }
    }
    new_inf <- unique(new_inf) # fix: avoid duplicates from multiple infected neighbors
    state[new_inf] <- 1
    if(length(new_inf) > 0){  # only record when there is new infection
      table <- rbind(table, data.frame(t=t, inf=new_inf))
    }
  }
  table
}

```

Now we run the simulations over different values. Since our critical
threshold was 0.00535, we select 2 values smaller than the threshold and
2 above.

```{r}

# set the thresholds, β, to test （lower than, close to, or higher than βc）
beta_vals <- c(0, 0.002, 0.005, beta_c, 0.01, 0.02, 0.1)

# keep recovery rate (mu) at 0.1
mu <- 0.1

# randomly set 1% as seeds - this is 12 nodes (of our 1133 total)
set.seed(123)
num_seeds <- ceiling(0.01 * vcount(graph))
seeds <- sample(1:vcount(graph), num_seeds)

# run n times of simulation for each β. Calculate infection total for each. 
n_runs <- 10
results <- data.frame()

for(beta in beta_vals){
  final_counts <- c()
  for(i in 1:n_runs){
    sim <- sim_sir(graph, beta, mu, seeds)
    final_counts <- c(final_counts, length(unique(sim$inf)))
  }
  avg_inf <- mean(final_counts)
  sd_inf <- sd(final_counts)
  results <- rbind(results, data.frame(beta=beta, avg_infected=avg_inf, sd=round(sd_inf,2)))
}
# and view the results:
results
```

Now we can plot the results to compare more easily:

```{r}
# viz：β vs averaged number of infected people
ggplot(results, aes(x=beta, y=avg_infected)) +
  geom_line(color="steelblue") +
  geom_point(size=3) +
  geom_errorbar(aes(ymin=avg_infected - sd, 
                    ymax=avg_infected + sd), 
                width=0.001, alpha=0.6) +
  labs(title = "Infection Size vs β (Random 1% Seeds)",
       x = expression(beta),
       y = "Average number of infected nodes") +
  theme_minimal()
```

The plot clearly demonstrates the presence of an **epidemic threshold**
in the network. When the infection rate β is below approximately
0.00535, the average number of infected nodes remains low, indicating
limited or failed spread. However, just beyond this value, there is a
**sudden and sharp increase** in the number of infections, revealing a
**nonlinear transition** typical of epidemic processes in complex
networks.

Furthermore, the plot shows a **monotonic increase** in the average
infection size as β increases, aligning with theoretical expectations
from the SIR model — higher infection rates naturally result in more
widespread diffusion. Notably, the **uncertainty (standard deviation)**
of infection size is highest around β = 0.01, suggesting that outcomes
near the threshold are highly sensitive to stochastic factors such as
seed selection and local network topology.

Overall, the plot illustrates a classic **epidemic threshold
phenomenon**. Once β exceeds the critical value, even a small increase
in the infection probability can lead to a disproportionately large
outbreak, confirming the nonlinear nature of spreading processes in
heterogeneous networks.

Now we plot the general trend to try identify smoothness (note that this
plot only has 1 run per point so could be considered less robust than
the previous).

```{r}
# set the seeds for consistency in the starting infection nodes:
set.seed(123)
num_seeds <- ceiling(0.01 * vcount(graph))
seeds <- sample(1:vcount(graph), num_seeds)

# plot the outputs over time
results <- map_dfr(seq(0,0.1,0.005), # beta range
        \(beta){
          realization <- sim_sir(graph,beta,mu,seeds) # make a realization for each beta
        data.frame(beta, 
                   ninf=nrow(realization)) # create dataframe column for beta and for number infected
        })

results %>% ggplot(aes(x=beta,y=ninf))+ 
  geom_point()+
  geom_line(color="red", alpha=0.5)+
  geom_vline(xintercept = beta_c,linetype=2)
```

We see the trend holds. There is a very sharp increase around the
critical threshold. Note that this value is very low and the increments
between each value in the plot are also small - each representing a 0.5%
increase in the beta threshold ($\beta = 0.005$).

With such a low critical threshold, we are very likely to end up with an
epidemic in this model. Any growth is likely to lead to an epidemic.

The basic reproduction number (R₀) when beta is 0.02:

```{r}
# Parameters
mu <- 0.1  # Recovery rate
beta <- 0.02  # Example infection rate (can try multiple values)

# Calculate R₀
R0 <- (beta / mu) * (mean_k2 / mean_k)

# Output result
paste0("Basic reproduction number R₀ ≈ ", round(R0, 3))
```

R₀ \> 1 means the epidemic is likely to spread. We obtained an R₀ of
3.738, that is, very probable to spread, when the infection probability
per contact per time step is only 2%.

<br> <br>

### 3) Choose a β well-above above βc. Using centrality , communities or any other suitable metric, find a better set of 1% of seeds in the network so we get more infected people than the random case. Measure the difference of your choice with the random case as:

#### a) The difference in the total number of infected people

#### b) The difference in the time of the peak of infection (when most infections happen).

First, we set our very high β. Since our actual threshold βc is VERY low
(\<0.01), we chose a beta value that may seem low but is actually very
high relative to our value.

We select β = 0.15

```{r}
# set the comparatively high beta
beta_high <- 0.15  

# Keep the same parameters and set our 
mu <- 0.1

# 1) Random seeds (baseline case)
set.seed(123)
num_seeds <- ceiling(0.01 * vcount(graph))
random_seeds <- sample(1:vcount(graph), num_seeds)

# 2) Strategic seed selection using different centrality measures

# Option 1: Degree centrality (nodes with most connections)
degree_cent <- degree(graph)
degree_seeds <- order(degree_cent, decreasing = TRUE)[1:num_seeds]

# Option 2: Betweenness centrality (nodes that bridge different parts)
betweenness_cent <- betweenness(graph)
betweenness_seeds <- order(betweenness_cent, decreasing = TRUE)[1:num_seeds]

# Option 3: Eigenvector centrality (nodes connected to important nodes)
eigen_cent <- eigen_centrality(graph)$vector
eigen_seeds <- order(eigen_cent, decreasing = TRUE)[1:num_seeds]

# Option 4: PageRank centrality
pagerank_cent <- page_rank(graph)$vector
pagerank_seeds <- order(pagerank_cent, decreasing = TRUE)[1:num_seeds]



```

Choose the centrality measure based on \_\_\_\_ because of \_\_\_\_\_

From this, we have our 1% of central nodes (which is equal to 12 nodes
in our data) and we now compare the random selection vs targeted
selection to see how rapidly the epidemic can spread.

```{r}
## run simulations based on each of the selected and random nodes
```

Plot together to compare trends in infection over time:

```{r}
## line plot with both matched, or 2 plots if we show each of susceptible, infected and recovered

```

Summary - we can show that targeted infection. I.e. those who are the
most influential in the email system being the first ones to spread the
rumor can make the rumor spread faster than if random people in the
network try to start the rumor.

### 4) Using the same β, design a “quarantine strategy”: at time step t=3 or 4, quarantine of 20% the susceptible population. You can model quarantine by temporally removing these nodes. Release the quarantined nodes 8 time steps later, making them susceptible again. Measure the difference with respect to no quarantine.

### 5) Suppose now that you can convince 5% of people in the network not to spread that information at all.

#### a) Choose those 5% randomly in the network. Simulate the SIR model above βc using 1% of the remaining nodes as seeds. Choose those seeds randomly.

#### b) Choose those 5% according to their centrality. Simulate the SIR model βc above using 1% of the remaining nodes as seeds. Choose those seeds randomly.

#### c) Measure the difference between both cases as you did in step 3.

### 6) Comment on the relationship between the findings in steps 3 and 5 using the same type of centrality for the 1% in step 3 and 5% in step 5.

### 7) With the results of step 2, train a model that predicts that time to infection of a node using their degree, centrality, betweeness, page rank and any other predictors you see fit. Use that model to select the seed nodes as those with the smallest time to infection in step 3. Repeat step 5 with this knowledge.
